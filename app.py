import streamlit as st
import pandas as pd
import numpy as np
from collections import Counter, defaultdict
from itertools import combinations
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import time

# -----------------------------------------------------------------------------
# [0] í˜ì´ì§€ ì„¤ì •
# -----------------------------------------------------------------------------
st.set_page_config(page_title="AI ë¡œë˜ ë¶„ì„ê¸° (Web)", layout="wide")
st.title("ğŸ± AI ë¡œë˜ ë²ˆí˜¸ ì¶”ì¶œê¸° (Pro)")

# -----------------------------------------------------------------------------
# [1] ë°ì´í„° ë¡œë“œ ë° AI í•™ìŠµ (ìºì‹± ì ìš©ìœ¼ë¡œ ì†ë„ í–¥ìƒ)
# -----------------------------------------------------------------------------
@st.cache_data
def load_and_preprocess_data(uploaded_file):
    try:
        df = pd.read_excel(uploaded_file, header=None)
        raw_data = df.iloc[:, 1:] # 1íšŒì°¨ë¶€í„° ë°ì´í„°ê°€ ìˆë‹¤ê³  ê°€ì •
        numeric_data = raw_data.apply(pd.to_numeric, errors='coerce')
        # 1~45 ì‚¬ì´ ìˆ«ìë§Œ í•„í„°ë§
        df_clean = numeric_data.where(numeric_data.ge(1) & numeric_data.le(45))
        
        if len(df_clean) < 50:
            return None, "ë°ì´í„° ë¶€ì¡± (ìµœì†Œ 50íšŒì°¨ ì´ìƒ í•„ìš”)"
            
        all_draws = [row.dropna().astype(int).tolist() for _, row in df_clean.iterrows()]
        # ê¶í•©ìˆ˜ ê³„ì‚°
        co_occurrence = Counter(pair for draw in all_draws for pair in combinations(sorted(draw), 2))
        
        return (df_clean, co_occurrence), "ì„±ê³µ"
    except Exception as e:
        return None, f"ì˜¤ë¥˜ ë°œìƒ: {e}"

@st.cache_resource
def train_ai_model(df):
    # í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    features = []
    for index, row in df.iterrows():
        draw = row.dropna().astype(int).tolist()
        if len(draw) < 6: continue
        features.append({
            'sum': sum(draw),
            'mean': sum(draw)/6,
            'std': pd.Series(draw).std(),
            'odd_count': sum(1 for n in draw if n % 2 != 0),
            'low_count': sum(1 for n in draw if 1 <= n <= 22),
            'ends_unique': len({n % 10 for n in draw})
        })
    
    if not features: return None
    
    X = pd.DataFrame(features)
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(X)
    
    # KMeans í´ëŸ¬ìŠ¤í„°ë§
    kmeans = KMeans(n_clusters=7, random_state=42, n_init=10)
    labels = kmeans.fit_predict(scaled_features)
    
    # íŒ¨í„´ ì „ì´ í•™ìŠµ
    transitions = {i: Counter() for i in range(7)}
    for i in range(len(labels) - 1):
        transitions[labels[i]][labels[i+1]] += 1
        
    return kmeans, scaler, labels, transitions

# -----------------------------------------------------------------------------
# [2] ì˜ˆì¸¡ ë¡œì§ í•¨ìˆ˜ ëª¨ìŒ
# -----------------------------------------------------------------------------
def predict_by_total_frequency(df, count=15):
    return pd.Series(df.dropna().values.flatten().astype(int)).value_counts().head(count).index.tolist()

def predict_by_recent_frequency(df, weeks=10, count=15):
    return pd.Series(df.tail(weeks).dropna().values.flatten().astype(int)).value_counts().head(count).index.tolist()

def predict_by_weighted_recent(df, span=20, count=15):
    scores = defaultdict(float)
    weights = np.exp(np.linspace(0, 1, len(df.tail(span)))) 
    recent_data = df.tail(span)
    for i, (_, row) in enumerate(recent_data.iterrows()):
        w = weights[i]
        for num in row.dropna().astype(int):
            scores[num] += w
    return [num for num, s in sorted(scores.items(), key=lambda x: x[1], reverse=True)[:count]]

def predict_by_neighbors(df, count=15):
    last_draw = df.iloc[-1].dropna().astype(int).tolist()
    neighbors = set()
    for n in last_draw:
        if n > 1: neighbors.add(n - 1)
        if n < 45: neighbors.add(n + 1)
    neighbors = neighbors - set(last_draw)
    return list(neighbors)

def predict_by_long_term_unappeared(df, count=15):
    last_appeared = {num: -1 for num in range(1, 46)}
    for index, row in df.iterrows():
        for num in row.dropna().astype(int): last_appeared[num] = index
    return [num for num, idx in sorted(last_appeared.items(), key=lambda item: item[1])[:count]]

def predict_by_good_compatibility(df, co_counts, count=15):
    last_draw = df.iloc[-1].dropna().astype(int).tolist()
    scores = {n: sum(co_counts.get(tuple(sorted((n, wn))), 0) for wn in last_draw) for n in range(1, 46) if n not in last_draw}
    return [num for num, score in sorted(scores.items(), key=lambda item: item[1], reverse=True)[:count]]

def predict_by_strongest_pairs(co_counts, count=5):
    return sorted({num for pair, freq in co_counts.most_common(count) for num in pair})

def predict_by_number_temperature(df, count=15):
    all_nums = pd.Series(df.dropna().values.flatten().astype(int))
    recent_nums = pd.Series(df.tail(10).dropna().values.flatten().astype(int))
    total_freq = all_nums.value_counts(normalize=True)
    recent_freq = recent_nums.value_counts(normalize=True)
    last_appeared = {num: len(df) for num in range(1, 46)}
    for i, row in df.iterrows():
        for num in row.dropna().astype(int): last_appeared[num] = i
    unappeared_period = pd.Series({num: len(df) - idx for num, idx in last_appeared.items()})
    if unappeared_period.max() > 0: unappeared_period /= unappeared_period.max()
    temp_scores = pd.Series({n: 0 for n in range(1, 46)})
    temp_scores = temp_scores.add(total_freq * 0.5, fill_value=0).add(recent_freq * 2.0, fill_value=0).add(unappeared_period * 0.8, fill_value=0)
    return temp_scores.sort_values(ascending=False).head(count).index.tolist()

def predict_by_positional_frequency(df, count_per_pos=5):
    sorted_draws = [sorted(r.dropna().astype(int).tolist()) for _, r in df.iterrows() if len(r.dropna()) == 6]
    if not sorted_draws: return []
    pos_counters = [Counter(col) for col in zip(*sorted_draws)]
    return sorted(list({num for c in pos_counters for num, _ in c.most_common(count_per_pos)}))

def predict_by_volatility_vector(df, anchor_count=5):
    all_vectors = [ [d[i+1]-d[i] for i in range(5)] for d in [sorted(r.dropna().astype(int).tolist()) for _, r in df.iterrows()] if len(d) == 6]
    if not all_vectors: return []
    avg_vector = [round(sum(col) / len(all_vectors)) for col in zip(*all_vectors)]
    anchor_points = predict_by_long_term_unappeared(df, anchor_count)
    predictions = set()
    for anchor in anchor_points:
        combo, num, is_valid = [anchor], anchor, True
        for interval in avg_vector:
            num += interval
            if num > 45: is_valid = False; break
            combo.append(num)
        if is_valid: predictions.update(combo)
    return sorted(list(predictions))

def predict_by_consecutive_pattern(df, weeks=3):
    last_draw = df.iloc[-1].dropna().astype(int).tolist()
    candidates = set()
    for n in last_draw:
        candidates.add(n-1); candidates.add(n+1)
    return sorted(list({n for n in candidates if 1 <= n <= 45} - set(last_draw)))

def predict_by_reappearing_number(df):
    return df.iloc[-1].dropna().astype(int).tolist()

def predict_by_prime_numbers(df, weeks=5):
    primes = {2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43}
    return sorted(list(primes))

def predict_by_number_zones(df, weeks=5):
    zones = {0: list(range(1, 11)), 1: list(range(11, 21)), 2: list(range(21, 31)), 3: list(range(31, 41)), 4: list(range(41, 46))}
    zone_counts = {i: 0 for i in range(5)}
    for num in df.tail(weeks).dropna().values.flatten().astype(int):
        for zid, nums in zones.items():
            if num in nums: zone_counts[zid] += 1; break
    min_count = min(zone_counts.values())
    return sorted([num for zid, cnt in zone_counts.items() if cnt == min_count for num in zones[zid]])

def predict_by_regression_cycle(df):
    predictions = []
    total_draws = len(df)
    for num in range(1, 46):
        appearances = df[df.isin([num])].count().max()
        if appearances < 2: continue
        avg_cycle = total_draws / appearances
        last_appeared_index = df.where(df == num).last_valid_index()
        if last_appeared_index is None: continue
        if total_draws - last_appeared_index > avg_cycle: predictions.append(num)
    return predictions

def predict_by_cluster_transition(df, model, scaler, labels, transitions, count=15):
    if any(x is None for x in [df, model, scaler, labels, transitions]): return []
    try:
        # ìµœê·¼ ë°ì´í„°ë¥¼ í”¼ì²˜ë¡œ ë³€í™˜
        features = []
        draw = df.tail(1).dropna().values.flatten().astype(int).tolist()
        features.append({
            'sum': sum(draw), 'mean': sum(draw)/6, 'std': pd.Series(draw).std(),
            'odd_count': sum(1 for n in draw if n % 2 != 0),
            'low_count': sum(1 for n in draw if 1 <= n <= 22),
            'ends_unique': len({n % 10 for n in draw})
        })
        last_cluster = model.predict(scaler.transform(pd.DataFrame(features)))[0]
        
        if not transitions[last_cluster]: return []
        next_cluster = transitions[last_cluster].most_common(1)[0][0]
        member_indices = [i for i, label in enumerate(labels) if label == next_cluster]
        if not member_indices: return []
        return pd.Series(df.iloc[member_indices].dropna().values.flatten().astype(int)).value_counts().head(count).index.tolist()
    except:
        return []

# -----------------------------------------------------------------------------
# [3] ìœ í‹¸ë¦¬í‹° ë° ì¡°í•© íƒìƒ‰
# -----------------------------------------------------------------------------
LOGIC_WEIGHTS = {
    1: 1.0, 2: 1.5, 3: 1.0, 4: 1.2, 5: 0.8, 6: 2.0, 7: 1.0, 8: 1.2,
    9: 1.0, 10: 1.0, 11: 0.5, 12: 0.8, 13: 1.0, 14: 2.5, 15: 1.5, 16: 1.5,
}

logic_info = [
    (1, "ì „ì²´ ê¸°ê°„ ë¹ˆë„ ìƒìœ„"), (2, "ìµœê·¼ 10ì£¼ ë¹ˆë„ ìƒìœ„"), (3, "ì¥ê¸° ë¯¸ì¶œìˆ˜"), (4, "ê¶í•©ìˆ˜ (vs ì§ì „íšŒì°¨)"),
    (5, "ê¶í•©ìˆ˜ (ìµœê°• ì¡°í•©)"), (6, "[í•µì‹¬] ìˆ«ì ì˜¨ë„ ë¶„ì„"), (7, "[ì‹ ê·œ] ìœ„ì¹˜ë³„ ë¹ˆë„"), (8, "[íšê¸°ì ] ë³€ë™ì„± ë²¡í„°"),
    (9, "[ì‹ ê·œ] ì—°ì†ìˆ˜ íŒ¨í„´"), (10, "ì´ì›”ìˆ˜ (ì§ì „ ë²ˆí˜¸)"), (11, "[ì‹ ê·œ] ì†Œìˆ˜(Prime) íŒ¨í„´"), (12, "[ì‹ ê·œ] ë²ˆí˜¸ëŒ€(Zone) ë¶„ì„"),
    (13, "íšŒê·€ ì£¼ê¸° ë¶„ì„"), (14, "[ê°•ë ¥] ê°€ì¤‘ì¹˜ ìµœê·¼ ë¹ˆë„"), (15, "[ê°•ë ¥] ì´ì›ƒìˆ˜ ë¶„ì„"), (16, "[AI] êµ°ì§‘ ì „í™˜ íŒ¨í„´")
]

def select_final_numbers(score_board, count):
    sorted_scores = sorted(score_board.items(), key=lambda x: x[1], reverse=True)
    all_candidates = [num for num, s in sorted_scores]
    if len(all_candidates) <= count: return all_candidates
    
    n_hot = int(count * 0.6)
    n_warm = int(count * 0.2)
    n_cold = count - n_hot - n_warm
    
    final_set = set()
    final_set.update(all_candidates[:n_hot])
    
    mid_start = n_hot
    mid_end = mid_start + n_warm + 5
    warm_pool = all_candidates[mid_start:mid_end]
    final_set.update(warm_pool[:n_warm])
    
    if n_cold > 0:
        cold_start = mid_end
        cold_pool = all_candidates[cold_start:cold_start+10]
        final_set.update(cold_pool[:n_cold])
        
    return sorted(list(final_set))

# -----------------------------------------------------------------------------
# [4] ë©”ì¸ UI
# -----------------------------------------------------------------------------
def main():
   # === [ë¹„ë°€ë²ˆí˜¸ ë³´ì•ˆ ê¸°ëŠ¥ ì‹œì‘] ===
    # ì—¬ê¸°ì— ì›í•˜ëŠ” ë¹„ë°€ë²ˆí˜¸ë¥¼ ì ìœ¼ì„¸ìš” (ì˜ˆ: "1234")
    my_password = "4938"
    
    # ì‚¬ì´ë“œë°”ì— ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ì°½ ë§Œë“¤ê¸°
    input_pw = st.sidebar.text_input("ğŸ”’ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
    
    if input_pw != my_password:
        st.sidebar.warning("ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ê±°ë‚˜ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()  # ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë¦¬ë©´ ì—¬ê¸°ì„œ í”„ë¡œê·¸ë¨ ì¤‘ë‹¨ (ì•„ë˜ ë‚´ìš© ì•ˆ ë³´ì—¬ì¤Œ)
    # === [ë¹„ë°€ë²ˆí˜¸ ë³´ì•ˆ ê¸°ëŠ¥ ë] ===
    st.sidebar.header("ğŸ“ ë°ì´í„° ë° ì„¤ì •")
    uploaded_file = st.sidebar.file_uploader("ë¡œë˜ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=['xlsx', 'xls'])
    
    # í…œí”Œë¦¿ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì œê³µ (ì„ íƒì‚¬í•­)
    # st.sidebar.download_button("ì—‘ì…€ ì–‘ì‹ ë‹¤ìš´ë¡œë“œ", ...) 

    if uploaded_file is not None:
        with st.spinner("ë°ì´í„° ë¶„ì„ ë° AI í•™ìŠµ ì¤‘..."):
            data_result, msg = load_and_preprocess_data(uploaded_file)
            
            if data_result is None:
                st.error(msg)
                return
            
            df, co_occurrence = data_result
            model_pack = train_ai_model(df)
            
            st.sidebar.success(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ! (ì´ {len(df)}íšŒì°¨)")
            st.sidebar.info("AI ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (K-Means)")
    else:
        st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë¡œë˜ ë‹¹ì²¨ë²ˆí˜¸ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return

    # íƒ­ êµ¬ì„±
    tab1, tab2 = st.tabs(["ğŸ¤– AI ìë™ ë¦¬í¬íŠ¸ (ì¶”ì²œ)", "ğŸ² ìˆ˜ë™ ì˜ˆì¸¡ ìƒì„±"])
    
    # --- [íƒ­ 1] AI ìë™ ë¦¬í¬íŠ¸ ---
    with tab1:
        st.subheader("ğŸ“Š AI ìµœì /ìµœì•… ì¡°í•© ë¶„ì„ ë¦¬í¬íŠ¸")
        st.caption("ìµœê·¼ 50íšŒì°¨(ì•½ 1ë…„) íŠ¸ë Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ì„±ì ì´ ì¢‹ì€ ë¡œì§ ì¡°í•©ì„ ìë™ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤.")
        
        target_count = st.slider("ì¶”ì¶œí•  ë²ˆí˜¸ ê°œìˆ˜ (ìµœì í™” ê¸°ì¤€)", 3, 15, 10, key="slider_auto")
        
        if st.button("ğŸš€ AI ë¶„ì„ ì‹œì‘ (ì‹œê°„ ì†Œìš”ë¨)"):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # 1. ëª¨ë“  ë¡œì§ ê²°ê³¼ ë¯¸ë¦¬ ê³„ì‚° (ì†ë„ ìµœì í™”)
            precalculated = {}
            model, scaler, labels, transitions = model_pack
            
            current_logics = {
                1: (predict_by_total_frequency, (df,)),
                2: (predict_by_recent_frequency, (df,)),
                3: (predict_by_long_term_unappeared, (df,)),
                4: (predict_by_good_compatibility, (df, co_occurrence)),
                5: (predict_by_strongest_pairs, (co_occurrence,)),
                6: (predict_by_number_temperature, (df,)),
                7: (predict_by_positional_frequency, (df,)),
                8: (predict_by_volatility_vector, (df,)),
                9: (predict_by_consecutive_pattern, (df,)),
                10: (predict_by_reappearing_number, (df,)),
                11: (predict_by_prime_numbers, (df,)),
                12: (predict_by_number_zones, (df,)),
                13: (predict_by_regression_cycle, (df,)),
                14: (predict_by_weighted_recent, (df,)),
                15: (predict_by_neighbors, (df,)),
                16: (predict_by_cluster_transition, (df, model, scaler, labels, transitions)),
            }
            
            for i in range(1, 17):
                func, args = current_logics[i]
                precalculated[i] = func(*args)
            
            # 2. ì¡°í•© íƒìƒ‰ (Streamlit Timeout ë°©ì§€ë¥¼ ìœ„í•´ íƒìƒ‰ ë²”ìœ„ ì¶•ì†Œ ì ìš©)
            past_draws = [set(row.dropna().astype(int)) for _, row in df.tail(50).iterrows()]
            all_logic_indices = list(range(1, 17))
            
            best_score = -1
            best_combo = []
            worst_score = float('inf')
            worst_combo = []
            
            # ëœë¤ ìƒ˜í”Œë§ ë°©ì‹ìœ¼ë¡œ ìµœì í™” (ì„œë²„ ë¶€í•˜ ë°©ì§€)
            import random
            random.seed(42)
            
            # ì „ì²´ ì¡°í•© ì¤‘ 1000ê°œë§Œ ìƒ˜í”Œë§í•˜ì—¬ í…ŒìŠ¤íŠ¸ (ì†ë„ vs ì •í™•ë„ íƒ€í˜‘)
            # í´ë¼ìš°ë“œ ë¬´ë£Œ ì„œë²„ëŠ” 30ì´ˆ ì´ìƒ ê±¸ë¦¬ë©´ ë©ˆì¶”ë¯€ë¡œ ì´ ë°©ì‹ì´ ì•ˆì „í•¨
            status_text.text("ì¡°í•© ì‹œë®¬ë ˆì´ì…˜ ì¤‘... (ì„œë²„ ìµœì í™” ëª¨ë“œ)")
            
            sample_combos = []
            for r in range(3, 8): # ë¡œì§ 3ê°œ~7ê°œ ì¡°í•©ë§Œ ë´„ (ë„ˆë¬´ ë§ìœ¼ë©´ ê³¼ì í•©)
                 combos = list(combinations(all_logic_indices, r))
                 if len(combos) > 200:
                     sample_combos.extend(random.sample(combos, 200))
                 else:
                     sample_combos.extend(combos)
            
            total_steps = len(sample_combos)
            
            for idx, combo_indices in enumerate(sample_combos):
                score_board = defaultdict(float)
                for l_idx in combo_indices:
                    candidates = precalculated[l_idx]
                    weight = LOGIC_WEIGHTS.get(l_idx, 1.0)
                    for rank, num in enumerate(candidates):
                        score_board[num] += (weight + (0.5 if rank < 5 else 0))
                
                final_numbers = set(select_final_numbers(score_board, target_count))
                
                score = 0
                for draw in past_draws:
                    matches = len(final_numbers.intersection(draw))
                    if matches >= 3: score += (10 ** (matches - 2)) # 3ê°œ:10, 4ê°œ:100, 5ê°œ:1000...
                
                if score > best_score:
                    best_score = score
                    best_combo = combo_indices
                if score < worst_score:
                    worst_score = score
                    worst_combo = combo_indices
                
                if idx % 100 == 0:
                    progress_bar.progress(idx / total_steps)
            
            progress_bar.progress(1.0)
            status_text.success("ë¶„ì„ ì™„ë£Œ!")
            
            # 3. ê²°ê³¼ ì¶œë ¥
            st.divider()
            
            # BEST ê²°ê³¼
            best_names = [next(name for i, name in logic_info if i == idx) for idx in best_combo]
            st.write(f"### ğŸ† ìµœì (Best) ì¡°í•©")
            st.info(f"**ì‚¬ìš©ëœ ë¡œì§:** {', '.join(best_names)}")
            
            best_score_board = defaultdict(float)
            for l_idx in best_combo:
                candidates = precalculated[l_idx]
                for rank, num in enumerate(candidates):
                    best_score_board[num] += (LOGIC_WEIGHTS.get(l_idx,1) + (0.5 if rank < 5 else 0))
            
            prediction = select_final_numbers(best_score_board, target_count)
            st.success(f"**ì¶”ì²œ ë²ˆí˜¸:** {sorted(prediction)}")
            
            # WORST ê²°ê³¼
            worst_names = [next(name for i, name in logic_info if i == idx) for idx in worst_combo]
            st.write(f"### â˜ ï¸ ìµœì•…(Worst) ì¡°í•© (ì œì™¸ìˆ˜ ì¶”ì²œ)")
            st.warning(f"**ì‚¬ìš©ëœ ë¡œì§:** {', '.join(worst_names)}")
            
            worst_score_board = defaultdict(float)
            for l_idx in worst_combo:
                candidates = precalculated[l_idx]
                for rank, num in enumerate(candidates):
                    worst_score_board[num] += (LOGIC_WEIGHTS.get(l_idx,1) + (0.5 if rank < 5 else 0))
            
            exclusion = select_final_numbers(worst_score_board, target_count)
            st.error(f"**ì œì™¸ ì¶”ì²œ ë²ˆí˜¸:** {sorted(exclusion)}")

    # --- [íƒ­ 2] ìˆ˜ë™ ì˜ˆì¸¡ ---
    with tab2:
        st.subheader("ğŸ› ï¸ ë¡œì§ ì§ì ‘ ì„ íƒ")
        
        cols = st.columns(2)
        selected_logics = []
        for i, (idx, name) in enumerate(logic_info):
            col = cols[0] if i < 8 else cols[1]
            if col.checkbox(name, value=(i in [0, 1, 5, 6, 7, 8, 10, 11, 13, 14, 15]), key=f"logic_{idx}"):
                selected_logics.append(idx)
        
        manual_count = st.slider("ì¶”ì¶œí•  ë²ˆí˜¸ ê°œìˆ˜", 3, 15, 6, key="slider_manual")
        
        if st.button("ğŸ² ë²ˆí˜¸ ìƒì„±"):
            if not selected_logics:
                st.warning("ìµœì†Œ 1ê°œ ì´ìƒì˜ ë¡œì§ì„ ì„ íƒí•˜ì„¸ìš”.")
            else:
                model, scaler, labels, transitions = model_pack
                current_logics = {
                    1: (predict_by_total_frequency, (df,)),
                    2: (predict_by_recent_frequency, (df,)),
                    3: (predict_by_long_term_unappeared, (df,)),
                    4: (predict_by_good_compatibility, (df, co_occurrence)),
                    5: (predict_by_strongest_pairs, (co_occurrence,)),
                    6: (predict_by_number_temperature, (df,)),
                    7: (predict_by_positional_frequency, (df,)),
                    8: (predict_by_volatility_vector, (df,)),
                    9: (predict_by_consecutive_pattern, (df,)),
                    10: (predict_by_reappearing_number, (df,)),
                    11: (predict_by_prime_numbers, (df,)),
                    12: (predict_by_number_zones, (df,)),
                    13: (predict_by_regression_cycle, (df,)),
                    14: (predict_by_weighted_recent, (df,)),
                    15: (predict_by_neighbors, (df,)),
                    16: (predict_by_cluster_transition, (df, model, scaler, labels, transitions)),
                }
                
                score_board = defaultdict(float)
                for idx in selected_logics:
                    func, args = current_logics[idx]
                    candidates = func(*args)
                    weight = LOGIC_WEIGHTS.get(idx, 1.0)
                    for rank, num in enumerate(candidates):
                        score_board[num] += (weight + (0.5 if rank < 5 else 0))
                
                final_nums = select_final_numbers(score_board, manual_count)
                
                st.divider()
                st.write("### ğŸ± ìƒì„± ê²°ê³¼")
                
                # ê³µ ëª¨ì–‘ìœ¼ë¡œ ì˜ˆì˜ê²Œ ì¶œë ¥
                html_code = ""
                for n in sorted(final_nums):
                    color = "#fbc400" if n <= 10 else "#69c" if n <= 20 else "#f72" if n <= 30 else "#aaa" if n <= 40 else "#b0d"
                    html_code += f"<span style='display:inline-block;background-color:{color};color:white;padding:10px;border-radius:50%;width:40px;height:40px;text-align:center;font-weight:bold;margin:5px;line-height:20px;'>{n}</span>"
                
                st.markdown(html_code, unsafe_allow_html=True)
                st.write("")
                st.info("ì„ íƒí•œ ë¡œì§ë“¤ì„ ì¢…í•©í•˜ì—¬ AIê°€ ì¶”ì²œí•œ ë²ˆí˜¸ì…ë‹ˆë‹¤.")

if __name__ == '__main__':

    main()
